{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from py3k_imports import * \n",
    "import project_imports3; reload(project_imports3); from project_imports3 import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pu.psettings(pd)\n",
    "pd.options.display.width = 200  # 150\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.keyboard_manager.command_shortcuts.add_shortcut('Ctrl-k','ipython.move-selected-cell-up')\n",
    "IPython.keyboard_manager.command_shortcuts.add_shortcut('Ctrl-j','ipython.move-selected-cell-down')\n",
    "IPython.keyboard_manager.command_shortcuts.add_shortcut('Shift-m','ipython.merge-selected-cell-with-cell-after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import inspect\n",
    "if sys.version_info.major > 2:\n",
    "    unicode = str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from py3k_imports import *\n",
    "from project_imports3 import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import autograd.numpy as np\n",
    "\n",
    "from operator import itemgetter as itg\n",
    "import toolz.curried as z\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi\n",
    "From [here](http://homepages.ulb.ac.be/~dgonze/TEACHING/viterbi.pdf)\n",
    "\n",
    "s = StringIO()\n",
    "states2.to_csv(s)\n",
    "s.seek(0)\n",
    "sc = s.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    from io import StringIO\n",
    "    csvstr = ''',H,L\n",
    "    A,0.2,0.3\n",
    "    C,0.3,0.2\n",
    "    G,0.3,0.2\n",
    "    T,0.2,0.3'''\n",
    "    states = pd.read_csv(StringIO(csvstr), index_col=0).T\n",
    "\n",
    "    sts = list(states.index)\n",
    "    start = [.5, .5]\n",
    "    transition = DataFrame([[.5, .5], [.4, .6]], columns=Series(sts, name='To'), index=Series(sts, name='From'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = [.5, .5]\n",
    "state_names = ['H', 'L']\n",
    "obs_names = list('ACGT')\n",
    "transition = DataFrame([[.5, .5], [.4, .6]],\n",
    "                       columns=Series(state_names, name='To'),\n",
    "                       index=Series(state_names, name='From'))\n",
    "states = DataFrame(\n",
    "    [[0.2, 0.3, 0.3, 0.2],\n",
    "     [0.3, 0.2, 0.2, 0.3]], index=state_names, columns=obs_names)\n",
    "\n",
    "log = np.log2\n",
    "startL, transitionL, statesL = map(log, [start, transition, states])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_table(s, startL, statesL, transitionL, convert_log=False):\n",
    "    \"\"\"\n",
    "    s: observed sequence\n",
    "    startL: initial state probabilities\n",
    "    statesL: p(obs_j | hidden state_i)\n",
    "    transitionL: p(transition to state_j|state_i)\n",
    "    \n",
    "    \"\"\"\n",
    "    if convert_log:\n",
    "        startL, statesL, transitionL = map(np.log, [startL, statesL, transitionL])\n",
    "    prev_path = DataFrame()\n",
    "    probs = DataFrame({0: startL + statesL[s[0]]})\n",
    "\n",
    "    for i, l in enumerate(s[1:], 1):\n",
    "        tocur = transitionL.add(probs[i-1], axis='index')  # p(current_state | each possible prev. state)\n",
    "        prev_path[i-1] = tocur.idxmax()\n",
    "        probs[i] = tocur.max() + statesL[l]  # p(current_state | most likely prev. state) * p(z|current_state)\n",
    "    return probs, prev_path\n",
    "\n",
    "def most_likely_path(probs, prev_path):\n",
    "    final_likely_state = probs.iloc[:, -1].idxmax()\n",
    "    backwards_path = [final_likely_state]\n",
    "\n",
    "    for c in reversed(list(prev_path)):\n",
    "        backwards_path.append(prev_path[c].ix[backwards_path[-1]])\n",
    "    mlp = backwards_path[::-1]\n",
    "    return mlp\n",
    "\n",
    "probs, prev_path = build_table('GGCACTGAA', startL, statesL, transitionL)\n",
    "mlp = most_likely_path(probs, prev_path)\n",
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/pos.train.txt','r') as f:\n",
    "    txt = f.read() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sents = filter(None, [zip(*[e.split() for e in sent.splitlines()]) for sent in txt[:].split('\\n\\n')])\n",
    "X = map(itg(0), sents)\n",
    "Y = map(itg(1), sents)\n",
    "tags = sorted({tag for y in Y for tag in y if tag.isalpha()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txt[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# common bigrams\n",
    "bigs = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for y in Y:\n",
    "    for t1, t2 in zip(y[:-1], y[1:]):\n",
    "        bigs[t1][t2] += 1\n",
    "        \n",
    "bigd = DataFrame(bigs).fillna(0)[tags].ix[tags]\n",
    "# bigd\n",
    "# sns.clustermap(bigd, annot=1, figsize=(16, 20), fmt='.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Series(Counter(y[0] for y in Y)).order(ascending=0)[:5]\n",
    "    Series(Counter(y[:2][-1] for y in Y)).order(ascending=0)[:4]\n",
    "\n",
    "    Series(Counter(y[-2:][0] for y in Y)).order(ascending=0)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wcts_all = defaultdict(Counter)\n",
    "for xi, yi in zip(X, Y):\n",
    "    for xw, yw in zip(xi, yi):\n",
    "        wcts_all[xw][yw] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wcts = z.valfilter(lambda x: sum(x.values()) > 4, wcts_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    stops = 'the of to a and in for that'.split()\n",
    "    stops = Series(stops)\n",
    "    z.reduceby()\n",
    "    def get_max(d):\n",
    "        k, v = max(d.items(), key=snd)\n",
    "        return k, v / sum(d.values())\n",
    "\n",
    "    get_max({'IN': 17, 'DT': 9202})\n",
    "    s = stops.map(z.comp(get_max, wcts.get)).reset_index(drop=0).set_index(stops)[0].order(ascending=0).drop('that', axis=0)\n",
    "    s\n",
    "    s.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "    cts = Series(z.valmap(lambda x: sum(x.values()), wcts))\n",
    "    cts.value_counts(normalize=1)\n",
    "    cts.order(ascending=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "' '.join(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algo\n",
    "\n",
    "$$\n",
    "p(\\bar y | \\bar x;w) =\n",
    "\\frac {1} {Z(\\bar x, w)}\n",
    "\\exp \\sum_j w_j F_j(\\bar x, \\bar y)\n",
    "$$\n",
    "\n",
    "$$\n",
    "F_j(\\bar x, \\bar y) = \n",
    "\\sum_{i=1}^n f_j(y_{i-1}, y_i, \\bar x, i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "# from utils import sum1, sum2, post_mr, mk_sum, F\n",
    "fs = AttrDict(fs)\n",
    "fsums = AttrDict(fsums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eq(x):\n",
    "    return lambda y: x == y\n",
    "\n",
    "def sch(term, x=False):\n",
    "    f = eq(term) if isinstance(term, (str, unicode)) else term\n",
    "    ss = X if x else Y\n",
    "    for i, s in enumerate(ss):\n",
    "        if any(f(t) for t in s):\n",
    "            yield X[i], Y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = sch('Mr.', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, y = g.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = X[0]\n",
    "y = Y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Argmax\n",
    "$\\newcommand{\\argmin}{\\operatornamewithlimits{argmin}}$\n",
    "Get $\\text{argmax}_{\\bar y} p(\\bar y | \\bar x;w) $\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ws = np.ones_like(fs.values())\n",
    "ws = z.valmap(const(1), fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "g_i(y_ {i-1}, y_i) = \\sum^J_{j=1} w_j f_j (y_ {i-1}, y_i, \\bar x, i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def gf(ws, yp, y, xbar, i):\n",
    "#     return sum(f(yp, y, xbar, i) * ws[fn] for fn, f in fs.items())\n",
    "\n",
    "def mkgf(ws, fs, tags, xbar):\n",
    "    #@z.curry\n",
    "    def gf(i):\n",
    "        def gfi(yp, y):\n",
    "            return sum(f(yp, y, xbar, i) * ws[fn] for fn, f in fs.items())\n",
    "        gfi.tags = tags\n",
    "        return gfi\n",
    "    return gf\n",
    "\n",
    "def getmat(gf):\n",
    "    df = DataFrame({ytag: {ytag_prev: gf(ytag_prev, ytag) for ytag_prev in gf.tags}\n",
    "                    for ytag in gf.tags})\n",
    "    df.columns.name, df.index.name = 'Y', 'Yprev'\n",
    "    return df\n",
    "xx = ['Mr.', 'Doo', 'in', 'a', 'circus']\n",
    "yy = ['NNP', 'NNP', 'IN', 'DT', 'IN']\n",
    "\n",
    "gf = mkgf(ws, fs, tags, xx)\n",
    "# gf = mkgf(ws, fs, tags, ['Mr.', 'Happy', 'derp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_mats():\n",
    "    xt = 'Hi this has Two capped words'.split()\n",
    "    testfs = z.keyfilter(lambda x: x == 'cap_nnp', fs)\n",
    "    stags = ['NNP', 'DT', 'IN', 'DERP']\n",
    "    wst = z.valmap(const(1), fs)\n",
    "\n",
    "    gft = mkgf(wst, testfs, stags, xt)\n",
    "    resmat = getmat(gft(0))\n",
    "\n",
    "    assert all(resmat.NNP == 1)\n",
    "    assert (resmat.drop('NNP', axis=1) == 0).all().all()\n",
    "    return 0\n",
    "\n",
    "def test_mats_2_args():\n",
    "    xt = 'Mr. Derp has Three capped words'.split()\n",
    "    testfs = z.keyfilter(lambda x: x in ('cap_nnp', 'post_mr'), fs)\n",
    "    stags = ['NNP', 'DT', 'IN', 'DERP']\n",
    "    wst = z.valmap(const(1), fs)\n",
    "\n",
    "    gft = mkgf(wst, testfs, stags, xt)\n",
    "    m0 = getmat(gft(0))\n",
    "    m1 = getmat(gft(1))\n",
    "\n",
    "    # First position should be the same\n",
    "    assert all(m0.NNP == 1)\n",
    "    assert (m0.drop('NNP', axis=1) == 0).all().all()\n",
    "    \n",
    "    # Second should get additional point from Mr. feature in position\n",
    "    # y-1 == NNP, y == NNP\n",
    "    assert m1.NNP.NNP == 2\n",
    "    # Subtracting that should give same matrix as original\n",
    "    m1c = m1.copy()\n",
    "    m1c.loc['NNP', 'NNP'] = m1.NNP.NNP - 1\n",
    "    assert_frame_equal(m1c, m0)\n",
    "    return gft\n",
    "    return 0\n",
    "\n",
    "test_mats()\n",
    "gft = test_mats_2_args()\n",
    "gf0 = gft(0)\n",
    "gf1 = gft(1)\n",
    "\n",
    "m0 = getmat(gft(0))\n",
    "m1 = getmat(gft(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gf1 = gf(1)\n",
    "gf0 = gf(0)\n",
    "gf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_u(m):\n",
    "    mu = m0.mean()\n",
    "    ymax = mu.idxmax()\n",
    "    return ymax, mu[ymax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mu = m0.mean()\n",
    "ymax = mu.idxmax()\n",
    "mu[ymax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_u(m0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u0 = getmat(gf(0)).mean()\n",
    "u0.iloc[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gf(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(u1.add(u0, axis='index')).iloc[:7,:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def s2df(xs: List[Series]) -> DataFrame:\n",
    "    return DataFrame({i: s for i, s in enumerate(xs)})\n",
    "\n",
    "def get_u(i: int, gf: \"int -> (Y, Y') -> float\"=gf, collect=True) -> '([max score], [max ix])':\n",
    "    \"\"\"Recursively build up g_i matrices bottom up, adding y-1 score\n",
    "    to get max y score. Returns score\n",
    "    \"\"\"\n",
    "    gmat = getmat(gf(i))\n",
    "    if not i:\n",
    "        return [gmat.mean()], [None]\n",
    "    uprevs, ixprevs = get_u(i - 1, gf=gf, collect=False)\n",
    "    uadd = gmat.add(uprevs[-1], axis='index')\n",
    "    retu, reti = uprevs + [uadd.max()], ixprevs + [uadd.idxmax()]\n",
    "    if not collect:\n",
    "        return retu, reti\n",
    "    return s2df(retu), s2df(reti)\n",
    "    \n",
    "u, i = get_u(4, collect=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def most_likely_path(u: 'DataFrame[float]', i: 'DataFrame[Y]') -> (List[str], List[float]):\n",
    "    revpath = []\n",
    "    revscore = []\n",
    "\n",
    "    for c in reversed(u.columns[:]):\n",
    "#         print(c)\n",
    "        ix = u[c].idxmax()\n",
    "        revscore.append(u[c][ix])\n",
    "        revpath.append(ix)\n",
    "        prevmax = i[c][ix]\n",
    "#         print('ix:', ix)\n",
    "#         print('prevmax:', prevmax)\n",
    "        if c:\n",
    "            assert u[c-1].max() == u[c-1][prevmax]\n",
    "    #     break\n",
    "    return revpath[::-1], revscore[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path, score = most_likely_path(uu, ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path, score = most_likely_path(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(xbar, ws, fs, tags):\n",
    "    gf = mkgf(ws, fs, tags, xbar)\n",
    "    u, i = get_u(len(xbar) - 1, gf=gf, collect=True)\n",
    "#     return u, i\n",
    "#     print(u)\n",
    "    path, score = most_likely_path(u, i)\n",
    "    return path, score\n",
    "    \n",
    "path2, score2 = predict(['Mr.', 'Doo', 'is', 'in', 'a', 'circus'], ws, fs, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict(['Mr.', 'Doo', 'in', 'a', 'circus'], ws, fs, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Gradient\n",
    "$$\\frac{\\partial}{\\partial w_j} \\log p(y | x;w) = F_j (x, y) - E_{y' \\sim  p(y | x;w) } [F_j(x,y')]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fsums.wd_a(xx, yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$U(k, v) = \\max_u [U(k-1, u) + g_k(u,v)]$$\n",
    "$$U(1, vec) = \\max_{y_0} [U(0, y_0) + g_k(y_0,vec)]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = '''$3,275 Individual $6,550 Family\n",
    "$2,000 Individual $4,000 Family\n",
    "$2,000 Individual $4,000 Family\n",
    "'''.splitlines()\n",
    "x = map(str.split, t)\n",
    "i = z.pipe(x, z.map(itg(0)), '\\t'.join)\n",
    "# i = map(itg(0), x)\n",
    "# f = map(itg(2), x)\n",
    "f\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
