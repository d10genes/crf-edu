{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wo crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from py3k_imports import * \n",
    "import project_imports3; reload(project_imports3); from project_imports3 import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pu.psettings(pd)\n",
    "pd.options.display.width = 150   # 200\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.keyboard_manager.command_shortcuts.add_shortcut('Ctrl-k','ipython.move-selected-cell-up')\n",
    "IPython.keyboard_manager.command_shortcuts.add_shortcut('Ctrl-j','ipython.move-selected-cell-down')\n",
    "IPython.keyboard_manager.command_shortcuts.add_shortcut('Shift-m','ipython.merge-selected-cell-with-cell-after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import inspect\n",
    "from typing import List, Dict, Tuple\n",
    "Df = Dict\n",
    "Y = str\n",
    "\n",
    "if sys.version_info.major > 2:\n",
    "    unicode = str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Series.__matmul__ = Series.dot\n",
    "DataFrame.__matmul__ = DataFrame.dot\n",
    "\n",
    "from matmul_new import test_matmul\n",
    "test_matmul()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/pos.train.txt','r') as f:\n",
    "    txt = f.read() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils; reload(utils); from utils import *\n",
    "# fs = AttrDict(fs)\n",
    "# fsums = AttrDict(fsums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sents = filter(None, [zip(*[e.split() for e in sent.splitlines()]) for sent in txt[:].split('\\n\\n')])\n",
    "X = map(itg(0), sents)\n",
    "Y_ = map(itg(1), sents)\n",
    "Xa = map(EasyList, X)\n",
    "Ya = map(AugmentY, Y_)\n",
    "tags = sorted({tag for y in Y_ for tag in y if tag.isalpha()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txt[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# common bigrams\n",
    "bigs = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for y in Y_:\n",
    "    for t1, t2 in zip(y[:-1], y[1:]):\n",
    "        bigs[t1][t2] += 1\n",
    "        \n",
    "bigd = DataFrame(bigs).fillna(0)[tags].ix[tags]\n",
    "# bigd\n",
    "# sns.clustermap(bigd, annot=1, figsize=(16, 20), fmt='.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wcts_all = defaultdict(Counter)\n",
    "for xi, yi in zip(X, Y_):\n",
    "    for xw, yw in zip(xi, yi):\n",
    "        wcts_all[xw][yw] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wcts = z.valfilter(lambda x: sum(x.values()) > 4, wcts_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "' '.join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "' '.join(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algo\n",
    "\n",
    "$$\n",
    "p(\\bar y | \\bar x;w) =\n",
    "\\frac {1} {Z(\\bar x, w)}\n",
    "\\exp \\sum_j w_j F_j(\\bar x, \\bar y)\n",
    "$$\n",
    "\n",
    "$$\n",
    "F_j(\\bar x, \\bar y) = \n",
    "\\sum_{i=1}^n f_j(y_{i-1}, y_i, \\bar x, i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Argmax\n",
    "\n",
    "Get $\\text{argmax}_{\\bar y} p(\\bar y | \\bar x;w)$. Since the scoring function only depends on 2 (consecutive in this situation) elements of $\\bar y$, argmax can be computed in polynomial time with a table ($\\in ℝ^{|Y| \\times |y|}$). $U_{ij}$ is the highest score for sequences ending in $y_i$ at position $y_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "g_i(y_ {i-1}, y_i) = \\sum^J_{j=1} w_j f_j (y_ {i-1}, y_i, \\bar x, i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "    # def gf(ws, yp, y, xbar, i):\n",
    "    #     return sum(f(yp, y, xbar, i) * ws[fn] for fn, f in fs.items())\n",
    "\n",
    "    x_ = ['Mr.', 'Doo', 'in', 'a', 'circus']\n",
    "    y_ = ['NNP', 'NNP', 'IN', 'DT', 'IN']\n",
    "\n",
    "    mkwts1 = lambda fs: z.valmap(const(1), fs)\n",
    "    ws = mkwts1(fs)\n",
    "\n",
    "    gf = mkgf(ws, fs, tags, x_)\n",
    "    # gf = mkgf(ws, fs, tags, ['Mr.', 'Happy', 'derp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate maximum score matrix U\n",
    "$$U(k, v) = \\max_u [U(k-1, u) + g_k(u,v)]$$\n",
    "$$U(1, vec) = \\max_{y_0} [U(0, y_0) + g_k(y_0,vec)]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_u(m0):\n",
    "    mu = m0.mean()\n",
    "    ymax = mu.idxmax()\n",
    "    return ymax, mu[ymax]\n",
    "\n",
    "\n",
    "def init_score(tags, tag=START, sort=True):\n",
    "    \"Base case for recurrent score calculation U\"\n",
    "    i = Series(0, index=sorted(tags) if sort else tags)\n",
    "    i.loc[tag] = 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    f = fs2['eq_wd1']\n",
    "    f('START', 'TAG1', xt2, 2)\n",
    "\n",
    "    F = Fs2['eq_wd2']\n",
    "    F(xt2, yt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils; reload(utils); from utils import *\n",
    "import crf; reload(crf); from crf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def s2df(xs: List[Series]) -> DataFrame:\n",
    "    return DataFrame({i: s for i, s in enumerate(xs)})\n",
    "\n",
    "def debugu(ufunc, gmat, uadd, gf, pt, k):\n",
    "    ufunc.gmat = gmat\n",
    "    ufunc.uadd = uadd\n",
    "    pt('\\n', k)\n",
    "    pt(gf.xbar[k], )\n",
    "    pt(gmat)\n",
    "    pt('\\nuadd')\n",
    "    pt(uadd)\n",
    "    \n",
    "def get_u(k: int=None, gf: \"int -> (Y, Y') -> float\"=None, collect=True, verbose=False) -> '([max score], [max ix])':\n",
    "    \"\"\"Recursively build up g_i matrices bottom up, adding y-1 score\n",
    "    to get max y score. Returns score.\n",
    "    - k is in terms of y vector, which is augmented with beginning and end tags\n",
    "    - also returns indices yprev that maximize y at each level to help reconstruct\n",
    "        most likely sequence\n",
    "    \"\"\"\n",
    "    pt = testprint(verbose)\n",
    "    imx = len(gf.xbar) + 1\n",
    "    if k is None:\n",
    "        pt(gf.xbar)\n",
    "        return get_u(imx, gf=gf, collect=1, verbose=verbose)\n",
    "    if k == 0:\n",
    "        return [init_score(gf.tags, START)], []\n",
    "\n",
    "    uprevs, ixprevs = get_u(k - 1, gf=gf, collect=False, verbose=verbose)\n",
    "    gmat = getmat(gf(k))\n",
    "    uadd = gmat.add(uprevs[-1], axis='index')\n",
    "    \n",
    "    if k > 0:\n",
    "        # START tag only possible at beginning.\n",
    "        # There should be a better way of imposing these constraints\n",
    "        uadd[START] = -1\n",
    "    if k < imx:\n",
    "        uadd[END] = -1  # END only possible at the...end\n",
    "    \n",
    "    if k == 1:\n",
    "        idxmax = Series(START, index=gf.tags)  # uadd.ix[START].idxmax()\n",
    "    else:\n",
    "        idxmax = uadd.idxmax()\n",
    "    pt('idxmax:', idxmax, sep='\\n')\n",
    "    retu, reti = uprevs + [uadd.max()], ixprevs + [idxmax]\n",
    "    if not collect:\n",
    "        return retu, reti\n",
    "    return s2df(retu), s2df(reti)\n",
    "\n",
    "\n",
    "def mlp(idxs, i: int=None, tagsrev: List[Y]=[END]) -> List[Y]:\n",
    "    \"Most likely sequence\"\n",
    "    if i is None:\n",
    "        return mlp(idxs, i=int(idxs.columns[-1]), tagsrev=tagsrev)\n",
    "    elif i < 0:\n",
    "        return tagsrev[::-1]\n",
    "    tag = tagsrev[-1]\n",
    "    yprev = idxs.loc[tag, i]\n",
    "    return mlp(idxs, i=i - 1, tagsrev=tagsrev + [yprev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import test; reload(test); from test import no_test_getu1, no_test_getu2, no_test_getu3, mk_fst\n",
    " \n",
    "no_test_getu1(get_u, mlp)\n",
    "no_test_getu2(get_u, mlp)\n",
    "no_test_getu3(get_u, mlp)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(xbar=None, fs=None, tags=None, ws=None, gf=None):\n",
    "    \"Return argmax_y with corresponding score\"\n",
    "    if gf is None:\n",
    "        ws = ws or mkwts1(fs)\n",
    "        gf = G(ws=ws, fs=fs, tags=tags, xbar=xbar)\n",
    "    u, i = get_u(gf=gf, collect=True, verbose=0)\n",
    "    path = mlp(i)\n",
    "    return path, u.ix[END].iloc[-1]\n",
    "    \n",
    "path2, score2 = predict(xbar=EasyList(['wd1', 'pre-end', 'whatevs']),\n",
    "                        fs=no_test_getu3.fs,\n",
    "                        tags=[START, 'TAG1', 'PENULTAG', END])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Gradient\n",
    "$$\\frac{\\partial}{\\partial w_j} \\log p(y | x;w) = F_j (x, y) - \\frac1 {Z(x, w)} \\sum_{y'} F_j (x, y') [\\exp \\sum_{j'} w_{j'} F_{j'} (x, y')]$$\n",
    "$$= F_j (x, y) - E_{y' \\sim  p(y | x;w) } [F_j(x,y')]$$\n",
    "\n",
    "\n",
    "### Forward-backward algorithm\n",
    "- Partition function $Z(\\bar x, w) = \\sum_{\\bar y} \\exp \\sum _{j=1} ^ J w_j F_j (\\bar x, \\bar y) $ can be intractible; forward-backward vectors can make it easier to compute\n",
    "   \n",
    "$$\\alpha (k + 1,v) = \\sum_u \\alpha (k,u)[\\exp g_{k+1}(u,v)] \\in ℝ^m$$\n",
    "$$\\alpha (0,y) = I(y=START)$$\n",
    "\n",
    "$$\\beta (u, k) = \\sum_v [\\exp g_{k+1} (u, v)] \\beta(v, k+1) $$\n",
    "$$\\beta (u, n+1) = I(u= END) $$\n",
    "\n",
    "Compute partition function $Z$ from either forward or backward vectors\n",
    "\n",
    "$$ Z(\\bar x, w) = \\beta(START, 0) $$\n",
    "$$ Z(\\bar x, w) = \\alpha(n+1, END) $$\n",
    "\n",
    "[There seems to be an error in the notes, which state that $Z(\\bar x, w) = \\sum_v \\alpha(n, v) $. If this is the case, $Z$ calculated with $\\alpha$ will never get a contribution from $g_{n+1}$, while $Z$ calculated with $\\beta$ will in the $\\beta(u, n)$ step.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check correctness of forward and backward vectors.\n",
    "- $ Z(\\bar x, w) = \\beta(START, 0) = \\alpha(n+1, END) $\n",
    "- For all positions $k=0...n+1$, $\\sum_u \\alpha(k, u) \\beta(u, k) = Z(\\bar x, w)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa = mk_asum(gf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lcsum, ssum, ak, np.exp(gnext)\n",
    "aa(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnext.mul?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gx = np.exp(gnext)\n",
    "side_by_side(gx, ak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gx.mul()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx = np.exp(gnext).mul(ak, axis=0).sum(axis=0)\n",
    "nx\n",
    "# .sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.exp(gnext).mul(ak).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_asum(gf, vb=False):\n",
    "    n = len(gf.xbar)\n",
    "    tags = gf.tags\n",
    "    p = testprint(vb)\n",
    "    \n",
    "    @memoize\n",
    "    def get_asum(knext=None):\n",
    "#         global ak, gnext\n",
    "        if knext is None:\n",
    "            # The first use of the forward vectors is to write\n",
    "            return get_asum(n+1)\n",
    "        if knext < 0:\n",
    "            raise ValueError('k ({}) cannot be negative'.format(k))\n",
    "        if knext == 0:\n",
    "            return init_score(tags, tag=START)\n",
    "        k = knext - 1\n",
    "        gnext = gf(knext).mat\n",
    "        ak = get_asum(k)\n",
    "\n",
    "        if vb:\n",
    "            names = 'exp[g{k1}] g{k1} a_{k}'.format(k1=knext, k=k).split()\n",
    "            p(side_by_side(np.exp(gnext), gnext, ak, names=names))\n",
    "#         lcsum = Series([sum([ak[u] * np.exp(gnext.loc[u, v]) for u in tags]) for v in tags], index=tags)\n",
    "        ssum = np.exp(gnext).mul(ak, axis=0).sum(axis=0)\n",
    "#         assert all(lcsum == ssum)\n",
    "        return ssum\n",
    "        return lcsum\n",
    "#         return Series([sum([ak[u] * np.exp(gnext.loc[u, v]) for u in tags]) for v in tags], index=tags)\n",
    "    return get_asum  #(knext, vb=vb)\n",
    "\n",
    "\n",
    "def mk_bsum(gf, vb=False):\n",
    "    p = testprint(vb)\n",
    "    n = len(gf.xbar)\n",
    "    tags = gf.tags\n",
    "    \n",
    "    @memoize\n",
    "    def get_bsum(k=None):\n",
    "        if k is None:\n",
    "            return get_bsum(0)\n",
    "        if k > n + 1:\n",
    "            raise ValueError('{} > length of x {} + 1'.format(k, n))\n",
    "        if k == n + 1:\n",
    "            return init_score(gf.tags, tag=END)\n",
    "        gnext = gf(k + 1).mat\n",
    "        bnext = get_bsum(k + 1)\n",
    "        if vb:\n",
    "            names = ['exp[g{}]'.format(k+1), 'g{}'.format(k+1), 'b_{}'.format(k+1)]\n",
    "            p(side_by_side(np.exp(gnext), gnext, bnext, names=names))\n",
    "#         lsum = Series([sum([np.exp(gnext.loc[u, v]) * bnext[v] for v in tags]) for u in tags], index=tags)\n",
    "        ssum = np.exp(gnext).mul(bnext, axis=1).sum(axis=1)\n",
    "        return ssum\n",
    "    return get_bsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit expectation2(gf, gfsub.fs['ly_VBZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit expectation2(gf, gfsub.fs['ly_VBZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit expectation2(gf, gfsub.fs['ly_VBZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_fwd_bkwd():\n",
    "    tgs = [START, 'TAG1', END]\n",
    "    x = EasyList(['wd1', 'pre-end'])\n",
    "    fs = {\n",
    "        # 'eq_wd1': mk_word_tag('wd1', 'TAG1'),\n",
    "        'pre_endx': lambda yp, y, x, i: (x[i - 1] == 'pre-end') and (y == END)\n",
    "         }\n",
    "    ws = z.merge(mkwts1(fs), {'pre_endx': 1})\n",
    "    gf = G(fs=fs, tags=tgs, xbar=x, ws=ws)\n",
    "\n",
    "    amkr = mk_asum(gf)\n",
    "    bmkr = mk_bsum(gf)\n",
    "    za = amkr().END\n",
    "    zb = bmkr().START\n",
    "    assert za == zb\n",
    "    \n",
    "    for k in range(len(x) + 2):\n",
    "        assert amkr(k) @ bmkr(k) == za\n",
    "    return za\n",
    "    \n",
    "test_fwd_bkwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate expected value of feature function\n",
    "Weighted by conditional probability of $y'$ given $x$\n",
    "$$E_{y' \\sim  p(y | x;w) } [F_j(x,y')]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sdot(s1: Series, s2: Series):\n",
    "    d1, d2 = s1.values[:, None], s2.values[:, None]\n",
    "    return d1 @ d2.T\n",
    "#     return DataFrame(d1 @ d2.T, columns=s1.index, index=s2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def expectation(gf, fj):\n",
    "#     tags = gf.tags\n",
    "#     n = len(gf.xbar)\n",
    "#     ss = 0\n",
    "#     asummer = mk_asum(gf)\n",
    "#     bsummer = mk_bsum(gf)\n",
    "    \n",
    "#     za = partition(asummer=asummer)\n",
    "    \n",
    "#     for i in range(1, n + 2):\n",
    "#         gfix = np.exp(gf(i).mat)\n",
    "#         alpha_vec = asummer(i - 1)\n",
    "#         beta_vec = bsummer(i)\n",
    "#         # alpha_vec = get_asum(gf, i - 1)\n",
    "#         # beta_vec = get_bsum(gf, i)\n",
    "#         for yprev in tags:\n",
    "#             α = alpha_vec[yprev]\n",
    "#             for y in tags:\n",
    "#                 ff = fj(yprev, y, gf.xbar, i)\n",
    "#                 β = beta_vec[y]\n",
    "#                 gfx = gfix.loc[yprev, y]\n",
    "#                 ss += ff * α * β * gfx\n",
    "#     return ss / za\n",
    "\n",
    "def expectation2(gf, fj):\n",
    "    tags = gf.tags\n",
    "    n = len(gf.xbar)\n",
    "    ss = 0\n",
    "    ss2 = 0\n",
    "    asummer = mk_asum(gf)\n",
    "    bsummer = mk_bsum(gf)\n",
    "    \n",
    "    za = partition(asummer=asummer)\n",
    "    global α, β, alpha_vec, beta_vec, gfix, smat\n",
    "    \n",
    "    def sumi(i):\n",
    "        gfix = np.exp(gf(i).mat.values)\n",
    "        alpha_vec = asummer(i - 1)\n",
    "        beta_vec = bsummer(i)\n",
    "        fmat = np.array([[fj(yprev, y, gf.xbar, i) for y in tags] for yprev in tags])\n",
    "        smat = sdot(alpha_vec, beta_vec) * gfix * fmat\n",
    "        return smat.sum() #.sum()\n",
    "    \n",
    "    return sum([sumi(i) for i in range(1, n + 2)]) / za\n",
    "        \n",
    "    for i in range(1, n + 2):\n",
    "        si = 0\n",
    "        gfix = np.exp(gf(i).mat)\n",
    "        alpha_vec = asummer(i - 1)\n",
    "        beta_vec = bsummer(i)\n",
    "        fmat = np.array([[fj(yprev, y, gf.xbar, i) for y in tags] for yprev in tags])\n",
    "        smat = sdot(alpha_vec, beta_vec) * gfix * fmat\n",
    "        #print(alpha_vec, tags)\n",
    "        for yprev in tags:\n",
    "            α = alpha_vec[yprev]\n",
    "            for y in tags:\n",
    "                ff = fj(yprev, y, gf.xbar, i)\n",
    "                β = beta_vec[y]\n",
    "                gfx = gfix.loc[yprev, y]\n",
    "                si += ff * α * β * gfx\n",
    "                ss += ff * α * β * gfx\n",
    "        print('sloop: {}, si: {}, smat: {}'.format(ss, si, smat.sum().sum()))\n",
    "    return ss / za\n",
    "\n",
    "def expectation_(gf, fj):\n",
    "    n = len(gf.xbar)\n",
    "    ss = 0\n",
    "    za = get_asum(gf).END\n",
    "\n",
    "    for i in range(1, n + 2):\n",
    "        gfix = np.exp(gf(i).mat)\n",
    "        alpha_vec = get_asum(gf, i - 1)\n",
    "        beta_vec = get_bsum(gf, i)\n",
    "        ss += sum(\n",
    "                [fj(yprev, y, gf.xbar, i) * alpha_vec[yprev] * gfix.loc[yprev, y] * beta_vec[y]\n",
    "                for yprev in tgs\n",
    "            for y in tgs])\n",
    "    return ss / za\n",
    "\n",
    "\n",
    "ee = 1\n",
    "\n",
    "# %time expectation(gf, fs['pre_endx'])\n",
    "# e1, e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit DataFrame(alpha_vec).dot(DataFrame(beta_vec).T)\n",
    "%timeit DataFrame(alpha_vec.values[:, None] @ beta_vec.values[:, None].T, columns=alpha_vec.index, index=alpha_vec.index)\n",
    "%timeit alpha_vec.values[:, None] @ beta_vec.values[:, None].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time expectation(gf, gfsub.fs['ly_VBZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time expectation2(gf, gfsub.fs['ly_VBZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%prun -qD profexp.prof expectation2(gf, gfsub.fs['ly_VBZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%prun -qD profexp.prof train(Zstrn, gfsub, maxiter=1, tol=.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Partial derivative\n",
    "###Probability function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partial_d(gf, fj, y, Fj=None) -> float:\n",
    "    f = fj if callable(fj) else gf.fs[fj]\n",
    "    if Fj is None:\n",
    "        Fj = FeatUtils.mk_sum(f)\n",
    "    ex1 = expectation(gf, f)\n",
    "    ex2 = expectation2(gf, f)\n",
    "    assert np.allclose(ex1, ex2)\n",
    "    return Fj(gf.xbar, y) - ex1\n",
    "\n",
    "\n",
    "def prob(gf, y, norm=True):\n",
    "    Fs = z.valmap(FeatUtils.mk_sum, gf.fs)\n",
    "    p = np.exp(sum([Fj(gf.xbar, y) * gf.ws[fname] for fname, Fj in Fs.items()]))\n",
    "    if not norm:\n",
    "        return p\n",
    "    za = partition(gf=gf)\n",
    "    return p / za\n",
    "     \n",
    "\n",
    "def partition(gf=None, asummer=None):\n",
    "    assert asummer or gf, 'Supply at least one argument'\n",
    "    asummer = asummer or mk_asum(gf)\n",
    "    return asummer().END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    import autograd.numpy as np\n",
    "    def probf(f, w):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    %time expectation(gf, fj)\n",
    "    %time expectation_(gf, fj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    %prun -qD profex.prof expectation2(gf, fj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%time expectation(gf, fj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = '''Nothing seems hard here .//NN VBZ JJ RB .\n",
    "The reason is cost .//DT NN VBZ NN .\n",
    "Terms were n't disclosed .//NNS VBD RB VBN .\n",
    "Mr. Juliano really really thinks so .//NNP NNP RB RB VBZ RB .\n",
    "Mr. Bill seems dead .//NNP NNP VBZ JJ .\n",
    "Young & Rubicam 's Pact//NNP CC NNP POS NNP\n",
    "Albany escaped embarrassingly unscathed .//NNP VBD RB JJ .'''\n",
    "\n",
    "corp3 = '''Nothing seems hard//NN VBZ JJ\n",
    "The reason is//VBZ NN VBZ\n",
    "Terms were n't//UNK UNK RB\n",
    "Mr. Juliano really really thinks//NNP NNP RB\n",
    "Mr. Bill seems//NNP NNP VBZ\n",
    "Young & Rubicam//NNP VBZ NNP\n",
    "Albany escaped embarrassingly//NNP UNK RB'''\n",
    "\n",
    "def mk_fx_tag(fx, tag):\n",
    "    def f(yp_, y, x, i):\n",
    "        return x[i] and fx(x[i]) and (y == tag)\n",
    "    f.__name__ = '{}(x)_{}'.format(fx, tag)\n",
    "    f.__doc__ = '{}(x[i]) and (y == {})'.format(fx, tag)\n",
    "    return f\n",
    "\n",
    "\n",
    "def mkgf(x=None, corpus=corpus):\n",
    "    xs, ys = process_corpus(corpus)\n",
    "    zs = zip(xs, ys)\n",
    "    tgs = sorted({y for ybar in ys for y in ybar.aug})\n",
    "\n",
    "    iscapped = lambda x: x and x[0].isupper()\n",
    "    fs = dict(\n",
    "        seems_VBZ=mk_word_tag('seems', 'VBZ'),\n",
    "        ly_VBZ=lambda yp, y, x, i: x[i] and x[i].endswith('ly') and (y == 'RB'),\n",
    "        cap_NN=mk_fx_tag(iscapped, 'NN'),\n",
    "        cap_NNP=mk_fx_tag(iscapped, 'NNP'),\n",
    "        nocap_START=lambda yp, y, x, i: x[i] and not iscapped(x[i]) and (yp == START),\n",
    "    #     cap_NN=lambda yp, y, x, i: iscapped(x[i]) and (y == 'NN'),\n",
    "    )\n",
    "    return G(fs=fs, tags=tgs, xbar=x or xs[-1], ws=mkwts1(fs, 1)), ys, zs\n",
    "\n",
    "def test_corp():\n",
    "    \n",
    "    gf, _, zs = mkgf(x=None, corpus=corpus)\n",
    "    Fs = z.valmap(FeatUtils.mk_sum, gf.fs)\n",
    "    \n",
    "    def runFs(Fj, zs=zs):\n",
    "        return [Fj(x, y) for x, y in zs]\n",
    "    \n",
    "    assert sum(runFs(Fs['ly_VBZ'])) == 3\n",
    "    assert sum(runFs(Fs['cap_NNP'])) == 8\n",
    "    assert sum(runFs(Fs['cap_NN'])) == 1\n",
    "    assert not sum(runFs(Fs['nocap_START']))\n",
    "    \n",
    "test_corp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Fs = z.valmap(FeatUtils.mk_sum, gf.fs)\n",
    "Fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Fj = Fs['ly_VBZ']\n",
    "Fj(gf.xbar, ybar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ybase = ys3[-1].aug[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ybase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yars = [[t] + ybase for t in gf.tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tgs = sorted(set(gf.tags) - {START, END})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All length-3 sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gf, ys3, zs3 = mkgf(corpus=corp3)\n",
    "fj = gf.fs['ly_VBZ']\n",
    "# partial_d(gf, fj, ys[-1], Fj=None)\n",
    "Y3 = [AugmentY([y1, y2, y3]) for y1 in tgs for y2 in tgs for y3 in tgs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list(enumerate(Y3))\n",
    "ybar = Y3[105]\n",
    "ybar\n",
    "prob(gf, ybar, norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y3[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "asummer = mk_asum(gf)\n",
    "side_by_side(asummer(0), asummer(1), asummer(2), asummer(3), asummer(4), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gcalc(gf, ybar):\n",
    "    return np.exp(sum([gf(i)(yp, y) for i, yp, y in zip(count(1), ybar.aug, ybar.aug[1:-1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpart = sum(gcalc(gf, y) for y in Y3)\n",
    "ps = sum([prob(gf, y, norm=False) for y in Y3])\n",
    "assert gpart == ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "side_by_side(gf(0).mat, np.exp(gf(0).mat), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nudge = lambda x, eps=.001: x + eps\n",
    "p1 = lambda x: x + 1\n",
    "bump = z.partial(nudge, eps=-.001)\n",
    "\n",
    "zs = zip(*process_corpus(corpus))\n",
    "for xi, yi in zs:\n",
    "    gf, _ = mkgf(x=xi)\n",
    "    for j in gf.fs:\n",
    "#         print(j)\n",
    "        ws2 = z.update_in(gf.ws, [j], bump)\n",
    "        gf2 = gf._replace(ws=ws2)\n",
    "        break\n",
    "\n",
    "print('ly in gf.xbar?:', any(map(lambda x: x.endswith('ly'), gf.xbar)))\n",
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gf.diff(gf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "gf = G(fs=fs, tags=tgs, xbar=x, ws=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gf, ys, zs = mkgf(corpus=corpus)\n",
    "fj = gf.fs['ly_VBZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FeatUtils.bookend = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "partial_d(gf, fj, x, y, Fj=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%prun -qD prof.prof partial_d(gf, fj, x, y, Fj=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zs[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "partial_d(gf, fj, zs[-1][1], Fj=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gf.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "λ = 1\n",
    "fj = gf.fs['ly_VBZ']\n",
    "# Fj = Fs['ly_VBZ']\n",
    "\n",
    "def train_(zs: List[Tuple[EasyList, AugmentY]],\n",
    "          fjid='ly_VBZ', fs=None, ws=None, vb=True, tgs=None):\n",
    "    fj = fs[fjid]\n",
    "    Fj = FeatUtils.mk_sum(fj)\n",
    "    pt = testprint(vb)\n",
    "    for x, y in zs:\n",
    "        gf_ = G(fs=fs, tags=tgs, xbar=x, ws=ws)\n",
    "        if not Fj(x, y):  # TODO: is this always right?\n",
    "            continue\n",
    "#         print(gf)\n",
    "#         print(gf_)\n",
    "        pder = partial_d(gf_, fj, y, Fj=Fj)\n",
    "        wj0 = ws[fjid]\n",
    "        ws[fjid] += λ * pder\n",
    "        pt('wj: {} -> {}'.format(wj0, ws[fjid]))\n",
    "        pt('pder: {:.2f}'.format(pder), Fj(x, y))\n",
    "    return ws\n",
    "\n",
    "def train_j(zs: List[Tuple[EasyList, AugmentY]],\n",
    "          fjid='ly_VBZ', fs=None, ws=None, tol=.01, maxiter=10, vb=True, tgs=None):\n",
    "    ws1 = ws\n",
    "    pt = testprint(vb)\n",
    "    \n",
    "    for i in count(1):\n",
    "        pt('Iter', i)\n",
    "        wj1 = ws1[fjid]\n",
    "        ws2 = train_(zs, fjid=fjid, fs=fs, ws=ws1, vb=vb, tgs=tgs)\n",
    "        wj2 = ws2[fjid]\n",
    "        if abs((wj2 - wj1) / wj1) < tol or (i >= maxiter):\n",
    "            return ws, i\n",
    "        ws1 = ws2\n",
    "        \n",
    "def train(zs, gf, ws=None, tol=.001, maxiter=10, vb=False):\n",
    "    wst = (ws or gf.ws).copy()\n",
    "    for fname, f in gf.fs.items():\n",
    "        wst, i = train_j(zs, fjid=fname, fs=gf.fs, ws=wst, tol=tol, maxiter=maxiter, vb=vb, tgs=gf.tags)\n",
    "        print(fname, 'trained in', i, 'iters: {:.2f}'.format(wst[fname]))\n",
    "        sys.stdout.flush()\n",
    "    return wst\n",
    "\n",
    "# %time ws1c = train(zs, gf, mkwts1(gf.fs, 1), maxiter=100, tol=.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Zs = zip(Xa, Ya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Zstrn = Zs[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ztst = Zs[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gfsub = gf._replace(fs=dict(ly_VBZ=gf.fs['ly_VBZ']))\n",
    "gfsub = gfsub._replace(ws=rand_weights(gfsub.fs), tags=sorted(tags + [START, END]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%prun -qD proftrn.prof train(Zstrn, gfsub, maxiter=1, tol=.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%prun -qD proftrn.prof train(Zstrn, gf._replace(tags=sorted(tags + [START, END]), ws=rand_weights(gf.fs)), maxiter=1, tol=.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time wst2b = train(Zstrn, gf._replace(tags=sorted(tags + [START, END]), ws=rand_weights(gf.fs)), maxiter=5, tol=.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time wst2 = train(Zstrn, gf._replace(tags=sorted(tags + [START, END]), ws=rand_weights(gf.fs)), maxiter=5, tol=.005)\n",
    "# %time wst = train(Zstrn, gf._replace(tags=sorted(tags + [START, END])), mkwts1(gf.fs, 1), maxiter=100, tol=.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ya[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gf_ = gf._replace(ws=wst2)\n",
    "for x, y in Ztst[:5]:\n",
    "    gfx = gf_._replace(xbar=x)\n",
    "    ypred, sc = predict(gf=gfx)\n",
    "    print(DataFrame(zip(gfx.xbar, ypred, y.aug)))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wst == {'cap_NN': 5.5770337170150999,\n",
    " 'cap_NNP': 6.5795482596835342,\n",
    " 'ly_VBZ': 7.1610907498951821,\n",
    " 'nocap_START': -4.0968133029466216,\n",
    " 'seems_VBZ': 1}\n",
    " \n",
    " wst2 == {'cap_NN': 5.6535298922935278,\n",
    " 'cap_NNP': 6.6593411043988899,\n",
    " 'ly_VBZ': 7.2107462564832634,\n",
    " 'nocap_START': -4.0972608563379938,\n",
    " 'seems_VBZ': 1.8675579901499675}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def likelihood(gf, zs, ws=None):\n",
    "    if ws:\n",
    "        gf = gf._replace(ws=ws)\n",
    "    return sum([prob(gf._replace(xbar=x), y, norm=False) for x, y in zs]) / (len(zs) * partition(gf))\n",
    "    for x, y in zs:\n",
    "        gfx = gf._replace(xbar=x, ws=ws1c)\n",
    "        print(prob(gfx, y, norm=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likelihood(gf, Ztst, ws=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rand_weights(gf.fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "partition(gf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likelihood(gf, Ztst, ws=ws1c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xa\n",
    "Ya\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x, y in zs:\n",
    "    gfx = gf._replace(xbar=x)\n",
    "    print(prob(gfx, y, norm=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x, y in zs:\n",
    "    gfx = gf._replace(xbar=x, ws=ws1c)\n",
    "    print(prob(gfx, y, norm=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob(gf, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ws1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_j(zs, fjid='ly_VBZ', ws=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time ws1 = train(zs, fs, mkwts1(fs, 1), maxiter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ws1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ws1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ws3 = train(zs, fs, mkwts1(fs, 1))\n",
    "ws3 = train(zs, fs, ws3, vb=False, maxiter=20, tol=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ws3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ws2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ws2 = train(zs, fjid='ly_VBZ', ws=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ws2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ws3 = train(zs, fjid='ly_VBZ', ws=ws2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ws3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ws2 = ws.copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gf.ws['ly_VBZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gf.ws['ly_VBZ'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gf._replace(ws=z.valmap(lambda x: x + 1, ws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gf.ws = ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for Fj "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fives = [(x, y) for x, y in zip(X, Y_) if len(x) == 5]\n",
    "fives = DataFrame(fives).applymap(' '.join)\n",
    "fives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Series(map(len, X)).value_counts(normalize=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
