{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from py3k_imports import * \n",
    "import project_imports3; reload(project_imports3); from project_imports3 import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pu.psettings(pd)\n",
    "pd.options.display.width = 150   # 200\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.keyboard_manager.command_shortcuts.add_shortcut('Ctrl-k','ipython.move-selected-cell-up')\n",
    "IPython.keyboard_manager.command_shortcuts.add_shortcut('Ctrl-j','ipython.move-selected-cell-down')\n",
    "IPython.keyboard_manager.command_shortcuts.add_shortcut('Shift-m','ipython.merge-selected-cell-with-cell-after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import inspect\n",
    "from typing import List\n",
    "Y = str\n",
    "\n",
    "if sys.version_info.major > 2:\n",
    "    unicode = str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from py3k_imports import *\n",
    "from project_imports3 import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import autograd.numpy as np\n",
    "\n",
    "from operator import itemgetter as itg\n",
    "import toolz.curried as z\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi\n",
    "From [here](http://homepages.ulb.ac.be/~dgonze/TEACHING/viterbi.pdf)\n",
    "\n",
    "s = StringIO()\n",
    "states2.to_csv(s)\n",
    "s.seek(0)\n",
    "sc = s.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    from io import StringIO\n",
    "    csvstr = ''',H,L\n",
    "    A,0.2,0.3\n",
    "    C,0.3,0.2\n",
    "    G,0.3,0.2\n",
    "    T,0.2,0.3'''\n",
    "    states = pd.read_csv(StringIO(csvstr), index_col=0).T\n",
    "\n",
    "    sts = list(states.index)\n",
    "    start = [.5, .5]\n",
    "    transition = DataFrame([[.5, .5], [.4, .6]], columns=Series(sts, name='To'), index=Series(sts, name='From'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = [.5, .5]\n",
    "state_names = ['H', 'L']\n",
    "obs_names = list('ACGT')\n",
    "transition = DataFrame([[.5, .5], [.4, .6]],\n",
    "                       columns=Series(state_names, name='To'),\n",
    "                       index=Series(state_names, name='From'))\n",
    "states = DataFrame(\n",
    "    [[0.2, 0.3, 0.3, 0.2],\n",
    "     [0.3, 0.2, 0.2, 0.3]], index=state_names, columns=obs_names)\n",
    "\n",
    "log = np.log2\n",
    "startL, transitionL, statesL = map(log, [start, transition, states])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_table(s, startL, statesL, transitionL, convert_log=False):\n",
    "    \"\"\"\n",
    "    s: observed sequence\n",
    "    startL: initial state probabilities\n",
    "    statesL: p(obs_j | hidden state_i)\n",
    "    transitionL: p(transition to state_j|state_i)\n",
    "    \n",
    "    \"\"\"\n",
    "    if convert_log:\n",
    "        startL, statesL, transitionL = map(np.log, [startL, statesL, transitionL])\n",
    "    prev_path = DataFrame()\n",
    "    probs = DataFrame({0: startL + statesL[s[0]]})\n",
    "\n",
    "    for i, l in enumerate(s[1:], 1):\n",
    "        tocur = transitionL.add(probs[i-1], axis='index')  # p(current_state | each possible prev. state)\n",
    "        prev_path[i-1] = tocur.idxmax()\n",
    "        probs[i] = tocur.max() + statesL[l]  # p(current_state | most likely prev. state) * p(z|current_state)\n",
    "    return probs, prev_path\n",
    "\n",
    "def most_likely_path(probs, prev_path):\n",
    "    final_likely_state = probs.iloc[:, -1].idxmax()\n",
    "    backwards_path = [final_likely_state]\n",
    "\n",
    "    for c in reversed(list(prev_path)):\n",
    "        backwards_path.append(prev_path[c].ix[backwards_path[-1]])\n",
    "    mlp = backwards_path[::-1]\n",
    "    return mlp\n",
    "\n",
    "probs, prev_path = build_table('GGCACTGAA', startL, statesL, transitionL)\n",
    "mlp = most_likely_path(probs, prev_path)\n",
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/pos.train.txt','r') as f:\n",
    "    txt = f.read() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sents = filter(None, [zip(*[e.split() for e in sent.splitlines()]) for sent in txt[:].split('\\n\\n')])\n",
    "X = map(itg(0), sents)\n",
    "Y_ = map(itg(1), sents)\n",
    "tags = sorted({tag for y in Y_ for tag in y if tag.isalpha()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txt[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# common bigrams\n",
    "bigs = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for y in Y_:\n",
    "    for t1, t2 in zip(y[:-1], y[1:]):\n",
    "        bigs[t1][t2] += 1\n",
    "        \n",
    "bigd = DataFrame(bigs).fillna(0)[tags].ix[tags]\n",
    "# bigd\n",
    "# sns.clustermap(bigd, annot=1, figsize=(16, 20), fmt='.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Series(Counter(y[0] for y in Y)).order(ascending=0)[:5]\n",
    "    Series(Counter(y[:2][-1] for y in Y)).order(ascending=0)[:4]\n",
    "\n",
    "    Series(Counter(y[-2:][0] for y in Y)).order(ascending=0)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wcts_all = defaultdict(Counter)\n",
    "for xi, yi in zip(X, Y_):\n",
    "    for xw, yw in zip(xi, yi):\n",
    "        wcts_all[xw][yw] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wcts = z.valfilter(lambda x: sum(x.values()) > 4, wcts_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    stops = 'the of to a and in for that'.split()\n",
    "    stops = Series(stops)\n",
    "    z.reduceby()\n",
    "    def get_max(d):\n",
    "        k, v = max(d.items(), key=snd)\n",
    "        return k, v / sum(d.values())\n",
    "\n",
    "    get_max({'IN': 17, 'DT': 9202})\n",
    "    s = stops.map(z.comp(get_max, wcts.get)).reset_index(drop=0).set_index(stops)[0].order(ascending=0).drop('that', axis=0)\n",
    "    s\n",
    "    s.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "    cts = Series(z.valmap(lambda x: sum(x.values()), wcts))\n",
    "    cts.value_counts(normalize=1)\n",
    "    cts.order(ascending=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "' '.join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "' '.join(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algo\n",
    "\n",
    "$$\n",
    "p(\\bar y | \\bar x;w) =\n",
    "\\frac {1} {Z(\\bar x, w)}\n",
    "\\exp \\sum_j w_j F_j(\\bar x, \\bar y)\n",
    "$$\n",
    "\n",
    "$$\n",
    "F_j(\\bar x, \\bar y) = \n",
    "\\sum_{i=1}^n f_j(y_{i-1}, y_i, \\bar x, i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils; reload(utils); from utils import *\n",
    "# from utils import sum1, sum2, post_mr, mk_sum, F\n",
    "fs = AttrDict(fs)\n",
    "fsums = AttrDict(fsums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eq(x):\n",
    "    return lambda y: x == y\n",
    "\n",
    "def sch(term, x=False):\n",
    "    f = eq(term) if isinstance(term, (str, unicode)) else term\n",
    "    ss = X if x else Y\n",
    "    for i, s in enumerate(ss):\n",
    "        if any(f(t) for t in s):\n",
    "            yield X[i], Y_[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Yb = map(FeatUtils.mkbookend, Y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0 = X[0]\n",
    "y0 = Y_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Argmax\n",
    "$\\newcommand{\\argmin}{\\operatornamewithlimits{argmin}}$\n",
    "Get $\\text{argmax}_{\\bar y} p(\\bar y | \\bar x;w) $\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ws = np.ones_like(fs.values())\n",
    "ws = z.valmap(const(1), fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "g_i(y_ {i-1}, y_i) = \\sum^J_{j=1} w_j f_j (y_ {i-1}, y_i, \\bar x, i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Df = Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def gf(ws, yp, y, xbar, i):\n",
    "#     return sum(f(yp, y, xbar, i) * ws[fn] for fn, f in fs.items())\n",
    "\n",
    "xx = ['Mr.', 'Doo', 'in', 'a', 'circus']\n",
    "yy = ['NNP', 'NNP', 'IN', 'DT', 'IN']\n",
    "gf = mkgf(ws, fs, tags, xx)\n",
    "# gf = mkgf(ws, fs, tags, ['Mr.', 'Happy', 'derp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "    test_mats()\n",
    "    gft = test_mats_2_args()\n",
    "    gf0 = gft(0)\n",
    "    gf1 = gft(1)\n",
    "\n",
    "    m0 = getmat(gft(0))\n",
    "    m1 = getmat(gft(1))\n",
    "\n",
    "    gf1 = gf(1)\n",
    "    gf0 = gf(0)\n",
    "    gf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate maximum score matrix U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_u(m0):\n",
    "    mu = m0.mean()\n",
    "    ymax = mu.idxmax()\n",
    "    return ymax, mu[ymax]\n",
    "\n",
    "def init_score(tags, tag=START):\n",
    "    \"Base case for recurrent score calculation U\"\n",
    "    i = Series(0, index=tags)\n",
    "    i.loc[tag] = 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    f = fs2['eq_wd1']\n",
    "    f('START', 'TAG1', xt2, 2)\n",
    "\n",
    "    F = Fs2['eq_wd2']\n",
    "    F(xt2, yt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def s2df(xs: List[Series]) -> DataFrame:\n",
    "    return DataFrame({i: s for i, s in enumerate(xs)})\n",
    "\n",
    "def debugu(ufunc, gmat, uadd, gf, pt, k):\n",
    "    ufunc.gmat = gmat\n",
    "    ufunc.uadd = uadd\n",
    "    pt('\\n', k)\n",
    "    pt(gf.xbar[k], )\n",
    "    pt(gmat)\n",
    "    pt('\\nuadd')\n",
    "    pt(uadd)\n",
    "    \n",
    "def get_u(k: int=None, gf: \"int -> (Y, Y') -> float\"=gf, collect=True, verbose=False) -> '([max score], [max ix])':\n",
    "    \"\"\"Recursively build up g_i matrices bottom up, adding y-1 score\n",
    "    to get max y score. Returns score.\n",
    "    - k is in terms of y vector, which is augmented with beginning and end tags\n",
    "    - also returns indices yprev that maximize y at each level to help reconstruct\n",
    "        most likely sequence\n",
    "    \"\"\"\n",
    "    pt = testprint(verbose)\n",
    "    imx = len(gf.xbar) + 1\n",
    "    if k is None:\n",
    "        pt(gf.xbar)\n",
    "        return get_u(imx, gf=gf, collect=1, verbose=verbose)\n",
    "    if k == 0:\n",
    "        return [init_score(gf.tags, START)], []\n",
    "\n",
    "    uprevs, ixprevs = get_u(k - 1, gf=gf, collect=False, verbose=verbose)\n",
    "    gmat = getmat(gf(k))\n",
    "    if k == imx and 0:\n",
    "        gmat = gmat[[END]]\n",
    "    uadd = gmat.add(uprevs[-1], axis='index')\n",
    "    if k > 0:\n",
    "        uadd[START] = -1  # START only possible at beginning\n",
    "    if k < imx:\n",
    "        uadd[END] = -1  # START only possible at beginning\n",
    "    \n",
    "    debugu(get_u, gmat, uadd, gf, pt, k)\n",
    "    if k == 1:\n",
    "        idxmax = Series(START, index=gf.tags)  # uadd.ix[START].idxmax()\n",
    "    else:\n",
    "        idxmax = uadd.idxmax()\n",
    "    pt('idxmax:', idxmax, sep='\\n')\n",
    "    retu, reti = uprevs + [uadd.max()], ixprevs + [idxmax]\n",
    "    if not collect:\n",
    "        return retu, reti\n",
    "    return s2df(retu), s2df(reti)\n",
    "\n",
    "\n",
    "# INIT = object()\n",
    "def mlp(idxs, i: int=None, tagsrev: List[Y]=[END]) -> List[Y]:\n",
    "    if i is None:\n",
    "        return mlp(idxs, i=int(idxs.columns[-1]), tagsrev=tagsrev)\n",
    "    elif i < 0:\n",
    "        return tagsrev[::-1]\n",
    "    tag = tagsrev[-1]\n",
    "    yprev = idxs.loc[tag, i]\n",
    "    # u.iloc[:, -1][tag]\n",
    "    \n",
    "    return mlp(idxs, i=i - 1, tagsrev=tagsrev + [yprev])\n",
    "\n",
    "# u2, i2 = get_u(gf=test_getu2.gf2, collect=True, verbose=1)\n",
    "# i2\n",
    "# u, k = get_u(4, collect=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_getu1():\n",
    "    tgs = [START, 'TAG1', END]\n",
    "    fs = {'eq_wd1': mk_word_tag('wd1', 'TAG1')}\n",
    "    ytpred = [START, 'TAG1', END]\n",
    "    x = EasyList(['wd1'])\n",
    "    \n",
    "    gf = mkgf(mkwts1(fs), fs, tgs, x)\n",
    "    u, i = get_u(gf=gf, collect=True)\n",
    "    assert (u.idxmax() == ytpred).all()\n",
    "    assert u.iloc[:, -1].max() == 2\n",
    "    \n",
    "def test_getu2():\n",
    "    tgs = [START, 'TAG1', END]\n",
    "    x2 = EasyList(['wd1', 'pre-end'])\n",
    "    fs = {'eq_wd1': mk_word_tag('wd1', 'TAG1'),\n",
    "          'pre_endx': lambda yp, y, x, i: (x[i - 1] == 'pre-end') and (y == END)}\n",
    "    ws = z.merge(mkwts1(fs), {'pre_endx': 3})\n",
    "    gf2 = mkgf(ws, fs, tgs, x2)\n",
    "    assert all(getmat(gf2(3))[END] == 3)\n",
    "    test_getu2.gf2 = gf2\n",
    "    test_getu2.fs = fs\n",
    "    u2, i2 = get_u(gf=gf2, collect=True, verbose=0)\n",
    "    print(u2)\n",
    "    assert (u2.idxmax() == [START, 'TAG1', 'TAG1', END]).all()\n",
    "    assert u2.iloc[:, -1].max() == 5\n",
    "    assert mlp(i2) == ['START', 'TAG1', 'TAG1', 'END']\n",
    "    return u2, i2\n",
    "    \n",
    "test_getu1()\n",
    "u, i = test_getu2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_getu3():\n",
    "    tgs = [START, 'TAG1', 'PENULTAG', END]\n",
    "    fs = {'eq_wd1': mk_word_tag('wd1', 'TAG1'),\n",
    "#           'pre_endx': lambda yp, y, x, i: (x[i - 1] == 'pre-end') and (y == END),\n",
    "          'pre_endy': lambda yp, y, x, i: (yp == 'PENULTAG') and (y == END),\n",
    "          'start_nonzero': lambda yp, y, x, i: (y == START) and (i != 0),\n",
    "          'start_zero': lambda yp, y, x, i: (y == START) and (i == 0),\n",
    "          'end_nonend': lambda yp, y, x, i: (y == END) and (i != (len(x) + 1)),\n",
    "          'end_end': lambda yp, y, x, i: (y == END) and (i == (len(x) + 1)),\n",
    "         }\n",
    "    ws = z.merge(mkwts1(fs), {'pre_endy': 3, 'start_nonzero': -1, 'end_nonend': -1})\n",
    "    x2 = EasyList(['wd1', 'pre-end', 'whatevs'])\n",
    "    gf2 = mkgf(ws, fs, tgs, x2)\n",
    "#     print(getmat(gf2(3)))\n",
    "    # assert all(getmat(gf2(3))[END] == 3)\n",
    "    test_getu3.gf2 = gf2\n",
    "    test_getu3.fs = fs\n",
    "    u2, i2 = get_u(gf=gf2, collect=True, verbose=0)\n",
    "#     assert (u2.idxmax() == [START, 'TAG1', END, END]).all()\n",
    "#     # 3rd value for predicted sequence is END, but only because it is first in index order\n",
    "#     assert u2[2].nunique() == 1, '3rd predicted tag should have same score for all v`s'\n",
    "#     assert u2.iloc[:, -1].max() == 5\n",
    "    assert mlp(i2) == ['START', 'TAG1', 'PENULTAG', 'PENULTAG', 'END']\n",
    "    return u2, i2\n",
    "\n",
    "u, i = test_getu3()\n",
    "g = test_getu3.gf2\n",
    "fs = test_getu3.fs\n",
    "f = fs['start_nonzero']\n",
    "# i\n",
    "x2 = EasyList(['wd1', 'pre-end', 'whatevs'])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def side_by_side(da, db):\n",
    "    d = da.copy()\n",
    "    d2 = DataFrame(db.copy())\n",
    "    d.columns = pd.MultiIndex.from_product([['A'], list(d)])\n",
    "    d2.columns = pd.MultiIndex.from_product([['B'], list(d2)])\n",
    "    d[d2.columns] = d2\n",
    "    return d\n",
    "\n",
    "def side_by_side(*ds):\n",
    "    dmultis = [side_by_side1(d, ctr=i) for i, d in enumerate(ds)]\n",
    "    return pd.concat(dmultis, axis=1)\n",
    "\n",
    "def side_by_side1(d, ctr=1):\n",
    "    d = DataFrame(d.copy())\n",
    "    d.columns = pd.MultiIndex.from_product([[ctr], list(d)])\n",
    "    return d\n",
    "    \n",
    "\n",
    "def side_by_side_(*objs, **kwds):\n",
    "    from pandas.core.common import adjoin\n",
    "    space = kwds.get('space', 4)\n",
    "    reprs = [repr(obj).split('\\n') for obj in objs]\n",
    "    print(adjoin(space, *reprs))\n",
    "def ff(m):\n",
    "    return side_by_side(m, m.idxmax(), m.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only need to keep max and idxmax at each level\n",
    "# y0 at level1 does not affect y2 at level 2 (but y1 will!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u2 = getmat(g(2))\n",
    "u2 = u2.add(u1.T, axis='index')\n",
    "u2i, u2m = u2.idxmax(), u2.max()\n",
    "side_bu_side(u2, u2i, u2m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u3 = getmat(g(3))\n",
    "ff(u3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u3.add(u2m, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u2.add(u1.T, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s2df(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils; reload(utils); from utils import *\n",
    "# from utils import sum1, sum2, post_mr, mk_sum, F\n",
    "fs = AttrDict(fs)\n",
    "fsums = AttrDict(fsums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    def post_mr(yp, y, x, i):  # optional keywords to not confuse mypy\n",
    "        return (y == yp == 'NNP') & (x[i - 1] == 'Mr.')\n",
    "\n",
    "    last_nn = lambda yp_, y, x, i: (i == len(x) - 1) and (y == 'NN')\n",
    "    last_nn = lambda yp, y, x, i: (yp == 'NNP') and (y == END)\n",
    "\n",
    "    F = mk_sum(post_mr)\n",
    "    # F(['wd0', 'Mr.', 'pre-end'], ['TAG3', 'NNP', 'NNP'])\n",
    "    F = mk_sum(last_nn)\n",
    "    F(['to', '1.23', 'the'], ['TO', 'CD', 'NN'])\n",
    "    xt2\n",
    "    yt2\n",
    "\n",
    "    def test_likely_path():\n",
    "        testfs_str = 'wd_to wd_of wd_for wd_in wd_a wd_the wd_and'.split()\n",
    "        testfs = z.keyfilter(lambda x: x in testfs_str, fs)\n",
    "        wst = mkwts1(testfs)\n",
    "        stags = 'Junk1 Junk2 TO IN DT CC Junk3 Junk4'.split()\n",
    "\n",
    "        xt = 'of for in the and a to'.split()\n",
    "        gft = mkgf(wst, testfs, stags, xt)\n",
    "        # gft = mkgf(wst, testfs, stags, xt)\n",
    "        u, i = get_u(gf=gft, collect=True)\n",
    "\n",
    "        shouldbe_dims = len(stags), len(xt)\n",
    "        assert u.shape == shouldbe_dims, ('Shape of score matrix is wrong. '\n",
    "                                          'Actual: {}, Expected: {}'.format(u.shape, shouldbe_dims))\n",
    "        assert most_likely_path(u, i) == [None, 'IN', 'IN', 'IN', 'DT', 'CC', 'DT', 'TO']\n",
    "\n",
    "    test_likely_path()\n",
    "\n",
    "    for i in range(1, len(yt2)):\n",
    "        print(i, end=' ')\n",
    "        print(yt2[i])\n",
    "\n",
    "    xt = 'Hi this has Two capped words'.split()\n",
    "    resmat = getmat(gft(0))\n",
    "    gft = mkgf()\n",
    "\n",
    "    def most_likely_path(u: 'DataFrame[float]', i: 'DataFrame[Y]') -> (List[str], List[float]):\n",
    "        revpath = []\n",
    "        revscore = []\n",
    "\n",
    "        for c in reversed(u.columns[:]):\n",
    "    #         print(c)\n",
    "            ix = u[c].idxmax()\n",
    "            revscore.append(u[c][ix])\n",
    "            revpath.append(ix)\n",
    "            prevmax = i[c][ix]\n",
    "    #         print('ix:', ix)\n",
    "    #         print('prevmax:', prevmax)\n",
    "            if c:\n",
    "                assert u[c-1].max() == u[c-1][prevmax]\n",
    "        #     break\n",
    "        return revpath[::-1], revscore[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path, score = most_likely_path(uu, ii)\n",
    "path, score = most_likely_path(u, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(xbar, ws, fs, tags):\n",
    "    gf = mkgf(ws, fs, tags, xbar)\n",
    "    u, i = get_u(len(xbar) - 1, gf=gf, collect=True)\n",
    "#     return u, i\n",
    "#     print(u)\n",
    "    path, score = most_likely_path(u, i)\n",
    "    return path, score\n",
    "    \n",
    "path2, score2 = predict(['Mr.', 'Doo', 'is', 'in', 'a', 'circus'], ws, fs, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict(['Mr.', 'Doo', 'in', 'a', 'circus'], ws, fs, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Gradient\n",
    "$$\\frac{\\partial}{\\partial w_j} \\log p(y | x;w) = F_j (x, y) - E_{y' \\sim  p(y | x;w) } [F_j(x,y')]$$\n",
    "\n",
    "$$\\alpha (0,y) = I(y=start)$$\n",
    "$$\\alpha (k + 1,v) = \\sum_u \\alpha (k,u)[\\exp g_{k+1}(u,v)] \\in ℝ^m$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts = Series(tags)\n",
    "y = yy\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V = ts\n",
    "v0 = v[0]\n",
    "v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 0\n",
    "# vi = \n",
    "y0 = y[0]\n",
    "a0 = Series(list(y0 == ts), index=ts)\n",
    "# a0.reset_index(drop=0)[:15].T.ix[[0]]\n",
    "a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gfa = mkgf(ws, fs, tags, xx)\n",
    "g1 = gfa(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del forwarder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(x, y, V, ws, fs) -> List[Series]:\n",
    "    \"\"\"Unnormalized probability of set of possible sequences that end at position\n",
    "    `col` with tag `row`\n",
    "    \"\"\"\n",
    "    mka = lambda x: Series(list(x), index=V)\n",
    "    mkg = mkgf(ws, fs, V, x)\n",
    "    def mkforward(i=0, aprevs=None):\n",
    "        if not i:\n",
    "            return mkforward(i=i + 1, aprevs=[mka(y[i] == V)])\n",
    "        if i >= len(y):\n",
    "            return aprevs\n",
    "        aprev = aprevs[-1]\n",
    "        gk = mkg(i)\n",
    "        ai = mka([sum(aprev[u] * np.e ** gk(u, v) for u in V) for v in V])\n",
    "        return mkforward(i=i + 1, aprevs=aprevs + [ai])\n",
    "    return DataFrame(mkforward()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z.operator.sub(1)(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward(x, y, V, ws, fs) -> List[Series]:\n",
    "    mksrs = lambda x: Series(list(x), index=V)\n",
    "    mkg = mkgf(ws, fs, V, x)\n",
    "    i_init = len(y)-1\n",
    "    i_fin = -1\n",
    "    nxt = lambda x: x - 1\n",
    "    \n",
    "    def mkprobvec(i=i_init, pprevs=None):\n",
    "        if i == i_init:\n",
    "            return mkprobvec(i=nxt(i), pprevs=[mksrs(y[i] == V)])\n",
    "        if i == i_fin:\n",
    "            return pprevs\n",
    "        pprev = pprevs[-1]\n",
    "        gk = mkg(i)\n",
    "        ai = mksrs([sum(pprev[inv] * np.e ** gk(outv, inv) for inv in V) for outv in V])\n",
    "        return mkprobvec(i=nxt(i), pprevs=pprevs + [ai])\n",
    "    return DataFrame(mkprobvec()[::-1]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DataFrame([xx, yy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bb = backward(xx, yy, ts, ws, fs)\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa = forward(xx, yy, ts, ws, fs)\n",
    "aa.iloc[:, -1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bb.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[sum(a0[u] * np.e ** g1(u, v) for u in ts) for v in ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[np.e ** sum(g1(u, v) for u in ts) for v in ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fsums.wd_a(xx, yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$U(k, v) = \\max_u [U(k-1, u) + g_k(u,v)]$$\n",
    "$$U(1, vec) = \\max_{y_0} [U(0, y_0) + g_k(y_0,vec)]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = '''$3,275 Individual $6,550 Family\n",
    "$2,000 Individual $4,000 Family\n",
    "$2,000 Individual $4,000 Family\n",
    "'''.splitlines()\n",
    "x = map(str.split, t)\n",
    "i = z.pipe(x, z.map(itg(0)), '\\t'.join)\n",
    "# i = map(itg(0), x)\n",
    "# f = map(itg(2), x)\n",
    "f\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
